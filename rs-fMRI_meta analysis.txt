import numpy as np
import pandas as pd
import statsmodels.stats.meta_analysis as sm

# Data
data = {
"Accuracy": [90.3, 88.0, 82.0, 76.6, 75.6, 73.7, 72.0, 70.7, 70.5, 69.6, 67.7, 72.7, 67.0, 65.9],
"Sensibilidad": [90.5, 88.0, 78.0, 51.7, 76.9, 82.7, 72.2, 90.8, 71.8, 71.5, 64.2, 83.2, 42.0, 68.1],
"Especificidad": [90.1, 91.0, 80.0, 83.3, 73.0, 92.8, 71.6, 79.2, 69.4, 68.2, 70.9, 73.6, 89.0, 67.1]
}

# DataFrame
df = pd.DataFrame(data)

# Descriptive statistics
stats = df.describe()

# Combined effect
meta_results = {}
for column in df.columns:
yi = df[column].values
vi = np.var(yi, ddof=1) / len(yi)
meta_results[column] = sm.combine_effects(yi, np.repeat(vi, len(yi)))
stats, meta_results
( Accuracy Sensibilidad Especificidad
count 14.000000 14.000000 14.000000
mean 74.450000 73.685714 78.514286
std 7.517953 14.142998 9.239618
min 65.900000 42.000000 67.100000
25% 69.825000 68.950000 71.075000
50% 72.350000 74.550000 76.400000
75% 76.350000 83.075000 87.575000
max 90.300000 90.800000 92.800000,
{'Accuracy': <statsmodels.stats.meta_analysis.CombineResults at 0x7fbdd43bd9d0>,
 'Sensibilidad': <statsmodels.stats.meta_analysis.CombineResults at 0x7fbdd42fd310>,
 'Especificidad': <statsmodels.stats.meta_analysis.CombineResults at 0x7fbdd43b1b10>})

DIAGRAM

import matplotlib.pyplot as plt
import numpy as np

# Data
accuracy = [90.3, 88.0, 82.0, 76.6, 75.6, 73.7, 72.0, 70.7, 70.5, 69.6, 67.7, 72.7, 67.0, 65.9]
sensitivity = [90.5, 88.0, 78.0, 51.7, 76.9, 82.7, 72.2, 90.8, 71.8, 71.5, 64.2, 83.2, 42.0, 68.1]
specificity = [90.1, 91.0, 80.0, 83.3, 73.0, 92.8, 71.6, 79.2, 69.4, 68.2, 70.9, 73.6, 89.0, 67.1]

# Means
means = [np.mean(accuracy), np.mean(sensitivity), np.mean(specificity)]
std_devs = [np.std(accuracy, ddof=1), np.std(sensitivity, ddof=1), np.std(specificity, ddof=1)]
labels = ['Accuracy', 'Sensitivity', 'Specificity']

# Plot
plt.figure(figsize=(10, 6))
plt.errorbar(means, range(len(means)), xerr=std_devs, fmt='o', color='black', ecolor='lightgray', elinewidth=3, capsize=0)
plt.yticks(range(len(means)), labels)
plt.axvline(x=np.mean(means), color='gray', linestyle='--')
plt.xlabel('Metric Value')
plt.title('Forest Plot of Metrics')
plt.gca().invert_yaxis()
plt.show()
10/7/25, 14:49 8-07-2025 Metha.ipynb - Colab
https://colab.research.google.com/drive/10uHJG83_89Zw4gELAlxjHjZk2Uwb877d?usp=sharing#printMode=true 1/3
Análisis de Heterogeneidad y Estimación Global
import numpy as np
import pandas as pd
from statsmodels.stats.meta_analysis import combine_effects
from scipy.stats import chi2

# Data
data = {
'N': [216, 947, 266, 587, 973, 619, 603, 464, 973, 947, 2972, 1594, 219, 1594],
'Accuracy': [90.3, 88.0, 82.0, 76.6, 75.6, 73.7, 72.0, 70.7, 70.5, 69.6, 67.7, 72.7, 67.0, 65.9],
'Sensibilidad': [90.5, 88.0, 78.0, 51.7, 76.9, 82.7, 72.2, 90.8, 71.8, 71.5, 64.2, 83.2, 42.0, 68.1],
'Especificidad': [90.1, 91.0, 80.0, 83.3, 73.0, 92.8, 71.6, 79.2, 69.4, 68.2, 70.9, 73.6, 89.0, 67.1]
}

# DataFrame
df = pd.DataFrame(data)

# Columns of interest
outcomes = ['Accuracy', 'Sensibilidad', 'Especificidad']
for outcome in outcomes:

# Individual effects (logarithmic transformation)
effects = np.log(df[outcome] / 100)

# Inverse variance
variances = 1 / df['N']
weights = 1 / variances

# Combined effects analysis
result = combine_effects(effects.values, variances.values, method_re="DL") # Asegurar que usamos valores numéricos

# Convert back to proportions
combined_effect = np.exp(result.effect)[0] * 100 # Extraer el valor numérico
stderr_combined = np.exp(np.sqrt(result.variance))[0] * 100 # Extraer el valor numérico

# Calculation of the Q statistic for heterogeneity
Q = np.sum(weights.values * (effects.values - result.effect)**2) # Asegurar que usamos valores numéricos
df_q = len(effects) - 1
p_value = 1 - chi2.cdf(Q, df_q)

# Calculation of I²
I2 = max(0, (Q - df_q) / Q) * 100 # Aseguramos que no sea negativo
10/7/25, 14:49 8-07-2025 Metha.ipynb - Colab
https://colab.research.google.com/drive/10uHJG83_89Zw4gELAlxjHjZk2Uwb877d?usp=sharing#printMode=true 2/3

# Results
print(f"{outcome} - Efecto combinado: {combined_effect:.2f}%, Error estándar: {stderr_combined:.2f}%")
print(f"{outcome} - Heterogeneidad (Q): {Q:.2f}, p-valor: {p_value:.2f}, I²: {I2:.2f}%")
print("\n")
Accuracy - Efecto combinado: 90.30%, Error estándar: 107.04%
Accuracy - Heterogeneidad (Q): 0.00, p-valor: 1.00, I²: 0.00%
Sensibilidad - Efecto combinado: 90.50%, Error estándar: 107.04%
Sensibilidad - Heterogeneidad (Q): 0.00, p-valor: 1.00, I²: 0.00%
Especificidad - Efecto combinado: 90.10%, Error estándar: 107.04%
Especificidad - Heterogeneidad (Q): 0.00, p-valor: 1.00, I²: 0.00%
/tmp/ipython-input-6-3474227607.py:42: RuntimeWarning: divide by zero encountered in scalar divide
 I2 = max(0, (Q - df_q) / Q) * 100 # Aseguramos que no sea negativo